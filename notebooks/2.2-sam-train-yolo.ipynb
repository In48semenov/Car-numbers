{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8e76f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/admin/PycharmProjects/ITMO/DL/Car_numbers/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "299a627f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\t\t .dockerignore\t LICENSE\t\t  segment\r\n",
      "..\t\t export.py\t models\t\t\t  setup.cfg\r\n",
      "benchmarks.py\t .git\t\t .pre-commit-config.yaml  train.py\r\n",
      "classify\t .gitattributes  __pycache__\t\t  tutorial.ipynb\r\n",
      "CONTRIBUTING.md  .github\t README.md\t\t  utils\r\n",
      "data\t\t .gitignore\t requirements.txt\t  val.py\r\n",
      "detect.py\t hubconf.py\t runs\t\t\t  yolov5s.pt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee1dbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=./models/custom_yolov5s.yaml, data=./data/dataset_number.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=500, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[10], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
      "YOLOv5 ðŸš€ v6.2-169-g959a466 Python-3.8.10 torch-1.12.1+cu102 CUDA:0 (NVIDIA GeForce GTX 1660 Ti, 5942MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs in Weights & Biases\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "custom_YOLOv5s summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
      "\n",
      "Transferred 342/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "freezing model.0.conv.weight\n",
      "freezing model.0.bn.weight\n",
      "freezing model.0.bn.bias\n",
      "freezing model.1.conv.weight\n",
      "freezing model.1.bn.weight\n",
      "freezing model.1.bn.bias\n",
      "freezing model.2.cv1.conv.weight\n",
      "freezing model.2.cv1.bn.weight\n",
      "freezing model.2.cv1.bn.bias\n",
      "freezing model.2.cv2.conv.weight\n",
      "freezing model.2.cv2.bn.weight\n",
      "freezing model.2.cv2.bn.bias\n",
      "freezing model.2.cv3.conv.weight\n",
      "freezing model.2.cv3.bn.weight\n",
      "freezing model.2.cv3.bn.bias\n",
      "freezing model.2.m.0.cv1.conv.weight\n",
      "freezing model.2.m.0.cv1.bn.weight\n",
      "freezing model.2.m.0.cv1.bn.bias\n",
      "freezing model.2.m.0.cv2.conv.weight\n",
      "freezing model.2.m.0.cv2.bn.weight\n",
      "freezing model.2.m.0.cv2.bn.bias\n",
      "freezing model.3.conv.weight\n",
      "freezing model.3.bn.weight\n",
      "freezing model.3.bn.bias\n",
      "freezing model.4.cv1.conv.weight\n",
      "freezing model.4.cv1.bn.weight\n",
      "freezing model.4.cv1.bn.bias\n",
      "freezing model.4.cv2.conv.weight\n",
      "freezing model.4.cv2.bn.weight\n",
      "freezing model.4.cv2.bn.bias\n",
      "freezing model.4.cv3.conv.weight\n",
      "freezing model.4.cv3.bn.weight\n",
      "freezing model.4.cv3.bn.bias\n",
      "freezing model.4.m.0.cv1.conv.weight\n",
      "freezing model.4.m.0.cv1.bn.weight\n",
      "freezing model.4.m.0.cv1.bn.bias\n",
      "freezing model.4.m.0.cv2.conv.weight\n",
      "freezing model.4.m.0.cv2.bn.weight\n",
      "freezing model.4.m.0.cv2.bn.bias\n",
      "freezing model.4.m.1.cv1.conv.weight\n",
      "freezing model.4.m.1.cv1.bn.weight\n",
      "freezing model.4.m.1.cv1.bn.bias\n",
      "freezing model.4.m.1.cv2.conv.weight\n",
      "freezing model.4.m.1.cv2.bn.weight\n",
      "freezing model.4.m.1.cv2.bn.bias\n",
      "freezing model.5.conv.weight\n",
      "freezing model.5.bn.weight\n",
      "freezing model.5.bn.bias\n",
      "freezing model.6.cv1.conv.weight\n",
      "freezing model.6.cv1.bn.weight\n",
      "freezing model.6.cv1.bn.bias\n",
      "freezing model.6.cv2.conv.weight\n",
      "freezing model.6.cv2.bn.weight\n",
      "freezing model.6.cv2.bn.bias\n",
      "freezing model.6.cv3.conv.weight\n",
      "freezing model.6.cv3.bn.weight\n",
      "freezing model.6.cv3.bn.bias\n",
      "freezing model.6.m.0.cv1.conv.weight\n",
      "freezing model.6.m.0.cv1.bn.weight\n",
      "freezing model.6.m.0.cv1.bn.bias\n",
      "freezing model.6.m.0.cv2.conv.weight\n",
      "freezing model.6.m.0.cv2.bn.weight\n",
      "freezing model.6.m.0.cv2.bn.bias\n",
      "freezing model.6.m.1.cv1.conv.weight\n",
      "freezing model.6.m.1.cv1.bn.weight\n",
      "freezing model.6.m.1.cv1.bn.bias\n",
      "freezing model.6.m.1.cv2.conv.weight\n",
      "freezing model.6.m.1.cv2.bn.weight\n",
      "freezing model.6.m.1.cv2.bn.bias\n",
      "freezing model.6.m.2.cv1.conv.weight\n",
      "freezing model.6.m.2.cv1.bn.weight\n",
      "freezing model.6.m.2.cv1.bn.bias\n",
      "freezing model.6.m.2.cv2.conv.weight\n",
      "freezing model.6.m.2.cv2.bn.weight\n",
      "freezing model.6.m.2.cv2.bn.bias\n",
      "freezing model.7.conv.weight\n",
      "freezing model.7.bn.weight\n",
      "freezing model.7.bn.bias\n",
      "freezing model.8.cv1.conv.weight\n",
      "freezing model.8.cv1.bn.weight\n",
      "freezing model.8.cv1.bn.bias\n",
      "freezing model.8.cv2.conv.weight\n",
      "freezing model.8.cv2.bn.weight\n",
      "freezing model.8.cv2.bn.bias\n",
      "freezing model.8.cv3.conv.weight\n",
      "freezing model.8.cv3.bn.weight\n",
      "freezing model.8.cv3.bn.bias\n",
      "freezing model.8.m.0.cv1.conv.weight\n",
      "freezing model.8.m.0.cv1.bn.weight\n",
      "freezing model.8.m.0.cv1.bn.bias\n",
      "freezing model.8.m.0.cv2.conv.weight\n",
      "freezing model.8.m.0.cv2.bn.weight\n",
      "freezing model.8.m.0.cv2.bn.bias\n",
      "freezing model.9.cv1.conv.weight\n",
      "freezing model.9.cv1.bn.weight\n",
      "freezing model.9.cv1.bn.bias\n",
      "freezing model.9.cv2.conv.weight\n",
      "freezing model.9.cv2.bn.weight\n",
      "freezing model.9.cv2.bn.bias\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/home/admin/PycharmProjects/ITMO/DL/Car_numbers/data/train.cach\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/home/admin/PycharmProjects/ITMO/DL/Car_numbers/data/val.cache' i\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.88 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
      "Plotting labels to runs/train/exp4/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/train/exp4\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      0/499      1.31G    0.05288    0.01235          0         27        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.928      0.936      0.957      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      1/499      4.52G    0.03391   0.007098          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.952      0.957      0.977      0.679\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      2/499      4.52G    0.02889   0.005747          0         26        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.953      0.971      0.981      0.734\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      3/499      4.52G    0.02418   0.005057          0         15        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.966      0.971      0.985      0.752\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      4/499      4.52G    0.02185   0.004726          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.966      0.971      0.988      0.775\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      5/499      4.52G    0.02082   0.004563          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011       0.97      0.961      0.988      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      6/499      4.52G    0.02016   0.004397          0         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.977      0.963      0.989       0.78\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      7/499      4.52G    0.01971   0.004337          0         18        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011       0.97      0.969      0.988      0.786\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      8/499      4.52G    0.01939   0.004325          0         22        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.972      0.969      0.986      0.779\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "      9/499      4.52G     0.0191   0.004276          0         14        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.978       0.97       0.99      0.795\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     10/499      4.52G    0.01893   0.004217          0         24        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.971      0.974      0.991      0.789\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     11/499      4.52G    0.01878   0.004189          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.975      0.972       0.99      0.788\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     12/499      4.52G    0.01856   0.004132          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.978      0.971       0.99      0.793\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     13/499      4.52G    0.01851   0.004154          0         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.974      0.974       0.99      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     14/499      4.52G    0.01836   0.004137          0         19        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.973      0.976       0.99      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     15/499      4.52G    0.01833   0.004096          0         17        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.969      0.979      0.989      0.796\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     16/499      4.52G    0.01821   0.004102          0         28        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.976      0.971      0.991        0.8\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     17/499      4.52G    0.01811   0.004002          0         13        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.976      0.976       0.99      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     18/499      4.52G      0.018   0.004031          0         29        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.971       0.98      0.991      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     19/499      4.52G    0.01782   0.004035          0         16        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.976      0.971       0.99      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     20/499      4.52G     0.0178   0.004054          0         20        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all       1922       2011      0.975      0.972      0.989      0.801\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "     21/499      4.52G    0.01784   0.003986          0         23        640:  "
     ]
    }
   ],
   "source": [
    "!python train.py --img 640 --batch 16 --epochs 500 --data ./data/dataset_number.yaml --cfg ./models/custom_yolov5s.yaml --weights yolov5s.pt --workers 8 --freeze 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45701b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589f37f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bfb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c165393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f6d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426fdda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
